{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM_s9qQTI1yz"
   },
   "source": [
    "# ðŸ§ª PyTorch Lab 6: RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z94g8D9qJCW8"
   },
   "source": [
    "# 1. Exploratory Data Analysis\n",
    "\n",
    "We will generate a dataset for forecasting using RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xzm0S5naGUIw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rTNVtWu_GdtV"
   },
   "outputs": [],
   "source": [
    "# Generate a sine wave dataset\n",
    "def generate_data(seq_length, num_samples):\n",
    "    x = np.linspace(0, 100, num_samples)\n",
    "    data = np.sin(x)\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        targets.append(data[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuCGQjlvGlCP"
   },
   "source": [
    "**Exercise** Explain with word what this function does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR6Hb24HJfi8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sw7-nZReJdhP"
   },
   "source": [
    "**Exercise** Use this function to generate 1000 sequences of size 30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KVPqPGEVJgIY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3r6fzTlBJedh"
   },
   "source": [
    "**Exercise** Plot several sequences with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEx7NhAGJgtx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhgHNDmKIUVK"
   },
   "source": [
    "# 2. Forecasting with a simple MLP\n",
    "\n",
    "First, we will use a simple multi layer perceptron to try to predict the y values, as we always do we put the data in a dataset and split using a dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRLkL665M6rs"
   },
   "source": [
    "**Exercise** Explain what is the task, including the dimension of input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snBcz-rZNNwD"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg5HLX7CNMCf"
   },
   "source": [
    "**Exercise** Complete the code such that it runs smoothly (replace the ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMeqXStBKqGL",
    "outputId": "795a6810-35de-47f0-d353-bd35388a66aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss train: 11.6197, Loss test: 0.0613\n",
      "Epoch [2/10], Loss train: 0.3972, Loss test: 0.0133\n",
      "Epoch [3/10], Loss train: 0.0653, Loss test: 0.0048\n",
      "Epoch [4/10], Loss train: 0.0124, Loss test: 0.0006\n",
      "Epoch [5/10], Loss train: 0.0031, Loss test: 0.0003\n",
      "Epoch [6/10], Loss train: 0.0015, Loss test: 0.0002\n",
      "Epoch [7/10], Loss train: 0.0011, Loss test: 0.0001\n",
      "Epoch [8/10], Loss train: 0.0007, Loss test: 0.0001\n",
      "Epoch [9/10], Loss train: 0.0005, Loss test: 0.0001\n",
      "Epoch [10/10], Loss train: 0.0004, Loss test: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ...\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()\n",
    "\n",
    "model = SimpleMLP()\n",
    "criterion = ...\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = ...\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ...\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        loss_test = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, targets)\n",
    "          loss_test += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss train: {loss_epoch:.4f}, Loss test: {loss_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RhvyG7zM1IH"
   },
   "source": [
    "# 2. Forecasting with an RNN\n",
    "\n",
    "Now we will use an RNN. We propose an implementaiton of a simple RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ugbmzEBN7iO"
   },
   "source": [
    "**Exercise** Explain below why the input dimension of the RNN layer is 1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O4XszPbOBYt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPqnnO3fQXv2"
   },
   "source": [
    "**Exercise** Run the follwoing and explain line a, b and c below. Use [pytorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alsafL5yLONo",
    "outputId": "4df51fcc-b98b-475b-df91-8cbedc6bc793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0480, 0.0483, 0.0527, 0.0491, 0.0502, 0.0549, 0.0552, 0.0531, 0.0477,\n",
       "        0.0479, 0.0552, 0.0552, 0.0545, 0.0553, 0.0549, 0.0509, 0.0487, 0.0490,\n",
       "        0.0552, 0.0549, 0.0552, 0.0475, 0.0551, 0.0552, 0.0481, 0.0553, 0.0547,\n",
       "        0.0533, 0.0475, 0.0475, 0.0497, 0.0475], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,hidden_size=256,num_layers=3):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(1, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, h = self.rnn(x) #out contains the output at each step, h is the final hidden state for each sequence\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.squeeze()\n",
    "\n",
    "model = RNNModel()\n",
    "\n",
    "X_temp,_ = next(iter(train_loader)) #Line a\n",
    "X_temp = X_temp.unsqueeze(-1) #Line b\n",
    "model(X_temp) #Line c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LgGHYOtTPTV"
   },
   "source": [
    "# It's training time ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReufbX2gN4U3",
    "outputId": "209ad682-8018-48af-a26f-f8ed881ea6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss train: 3.7127, Loss test: 0.0512\n",
      "Epoch [2/10], Loss train: 0.1487, Loss test: 0.0038\n",
      "Epoch [3/10], Loss train: 0.0148, Loss test: 0.0012\n",
      "Epoch [4/10], Loss train: 0.0048, Loss test: 0.0010\n",
      "Epoch [5/10], Loss train: 0.0028, Loss test: 0.0008\n",
      "Epoch [6/10], Loss train: 0.0023, Loss test: 0.0005\n",
      "Epoch [7/10], Loss train: 0.0023, Loss test: 0.0006\n",
      "Epoch [8/10], Loss train: 0.0026, Loss test: 0.0004\n",
      "Epoch [9/10], Loss train: 0.0018, Loss test: 0.0003\n",
      "Epoch [10/10], Loss train: 0.0015, Loss test: 0.0003\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epoch = 0\n",
    "    for seq, target in train_loader:\n",
    "        seq = seq.unsqueeze(-1)  # Add feature dimension\n",
    "        output = model(seq)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        loss_test = 0\n",
    "        for seq, target in test_loader:\n",
    "          seq = seq.unsqueeze(-1)  # Add feature dimension\n",
    "          output = model(seq)\n",
    "          loss = criterion(output, target)\n",
    "          loss_test += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss train: {loss_epoch:.4f}, Loss test: {loss_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcL3Ij1RUeAd"
   },
   "source": [
    "# 3. Doing next time step prediciton in an autoregressive way\n",
    "\n",
    "Now, we switch paradigme, and instead of using 30 time step to predict the 31st, we to x_{0:t} to x_{t+1}. It is easy to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eand4AWbEGR"
   },
   "source": [
    "**Exercise** Implement and run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdA5sFa6chiV"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
